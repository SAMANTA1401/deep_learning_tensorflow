{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "The tf.distribute.Strategy API provides an abstraction for distributing your training across multiple processing units. It allows you to carry out distributed training using existing models and training code with minimal changes.\n",
    "\n",
    "This tutorial demonstrates how to use the tf.distribute.MirroredStrategy to perform in-graph replication with synchronous training on many GPUs on one machine. The strategy essentially copies all of the model's variables to each processor. Then, it uses all-reduce to combine the gradients from all processors, and applies the combined value to all copies of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MirroredStrategy trains your model on multiple GPUs on a single machine. For synchronous training on many GPUs on multiple workers, use the tf.distribute.MultiWorkerMirroredStrategy with the Keras Model.fit or a custom training loop. For other options, refer to the Distributed training guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "# Load the TensorBoard notebook extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to d:\\a27_YEARS_OLD\\deep_learning\\distributed_training\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\a27_YEARS_OLD\\deep_learning\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.23 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.13 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.08 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.07 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.98 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.98 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.98 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.98 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.98 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.98 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.98 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.98 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.98 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.98 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.98 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.98 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.98 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.98 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.98 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  1.98 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  1.92 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  1.92 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  1.92 url/s]\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:02<00:00,  1.38 file/s]\n",
      "Dl Size...: 100%|██████████| 10/10 [00:02<00:00,  3.44 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  1.37 url/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to d:\\a27_YEARS_OLD\\deep_learning\\distributed_training\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "datasets, info = tfds.load(name='mnist', with_info=True, data_dir=os.getcwd(), as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = datasets['train'], datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(28, 28, 1), dtype=uint8, numpy=\n",
       " array([[[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 84],\n",
       "         [254],\n",
       "         [101],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [174],\n",
       "         [253],\n",
       "         [119],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 31],\n",
       "         [247],\n",
       "         [202],\n",
       "         [ 29],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  1],\n",
       "         [  1],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [141],\n",
       "         [253],\n",
       "         [168],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 66],\n",
       "         [208],\n",
       "         [ 56],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [186],\n",
       "         [253],\n",
       "         [120],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 57],\n",
       "         [253],\n",
       "         [119],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 28],\n",
       "         [249],\n",
       "         [240],\n",
       "         [ 25],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 34],\n",
       "         [253],\n",
       "         [119],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [109],\n",
       "         [254],\n",
       "         [197],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 53],\n",
       "         [253],\n",
       "         [119],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [135],\n",
       "         [254],\n",
       "         [133],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [133],\n",
       "         [254],\n",
       "         [119],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 27],\n",
       "         [240],\n",
       "         [255],\n",
       "         [ 35],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  7],\n",
       "         [235],\n",
       "         [253],\n",
       "         [208],\n",
       "         [151],\n",
       "         [169],\n",
       "         [215],\n",
       "         [253],\n",
       "         [206],\n",
       "         [  2],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 97],\n",
       "         [253],\n",
       "         [253],\n",
       "         [253],\n",
       "         [254],\n",
       "         [253],\n",
       "         [253],\n",
       "         [253],\n",
       "         [ 86],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [150],\n",
       "         [244],\n",
       "         [145],\n",
       "         [119],\n",
       "         [101],\n",
       "         [ 82],\n",
       "         [253],\n",
       "         [253],\n",
       "         [ 14],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 84],\n",
       "         [254],\n",
       "         [172],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [174],\n",
       "         [253],\n",
       "         [119],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [237],\n",
       "         [252],\n",
       "         [ 56],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 50],\n",
       "         [241],\n",
       "         [182],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [187],\n",
       "         [254],\n",
       "         [249],\n",
       "         [105],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [186],\n",
       "         [253],\n",
       "         [206],\n",
       "         [ 21],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [227],\n",
       "         [242],\n",
       "         [ 32],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [236],\n",
       "         [219],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]]], dtype=uint8)>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=4>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(mnist_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Define the distribution strategy\n",
    "Create a MirroredStrategy object. This will handle distribution and provide a context manager (MirroredStrategy.scope) to build your model inside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the input pipeline\n",
    "When training a model with multiple GPUs, you can use the extra computing power effectively by increasing the batch size. In general, use the largest batch size that fits the GPU memory and tune the learning rate accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also do info.splits.total_num_examples to get the total\n",
    "# number of examples in the dataset.\n",
    "\n",
    "num_train_examples = info.splits['train'].num_examples\n",
    "num_test_examples = info.splits['test'].num_examples\n",
    "\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 16\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that normalizes the image pixel values from the [0, 255] range to the [0, 1] range (feature scaling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image /= 255\n",
    "\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this scale function to the training and test data, and then use the tf.data.Dataset APIs to shuffle the training data (Dataset.shuffle), and batch it (Dataset.batch). Notice that you are also keeping an in-memory cache of the training data to improve performance (Dataset.cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\a27_YEARS_OLD\\deep_learning\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">346,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m346,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">347,146</span> (1.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m347,146\u001b[0m (1.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">347,146</span> (1.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m347,146\u001b[0m (1.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(None, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this toy example with the MNIST dataset, you will be using the Adam optimizer's default learning rate of 0.001.\n",
    "\n",
    "For larger datasets, the key benefit of distributed training is to learn more in each training step, because each step processes more training data in parallel, which allows for a larger learning rate (within the limits of the model and dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the callbacks\n",
    "Define the following Keras Callbacks:\n",
    "\n",
    "tf.keras.callbacks.TensorBoard: writes a log for TensorBoard, which allows you to visualize the graphs.\n",
    "tf.keras.callbacks.ModelCheckpoint: saves the model at a certain frequency, such as after every epoch.\n",
    "tf.keras.callbacks.BackupAndRestore: provides the fault tolerance functionality by backing up the model and current epoch number. Learn more in the Fault tolerance section of the Multi-worker training with Keras tutorial.\n",
    "tf.keras.callbacks.LearningRateScheduler: schedules the learning rate to change after, for example, every epoch/batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint directory to store the checkpoints.\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Define the name of the checkpoint files.\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for decaying the learning rate.\n",
    "# You can define any decay function you need.\n",
    "def decay(epoch):\n",
    "  if epoch < 3:\n",
    "    return 1e-3\n",
    "  elif epoch >= 3 and epoch < 7:\n",
    "    return 1e-4\n",
    "  else:\n",
    "    return 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a callback for printing the learning rate at the end of each epoch.\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    print('\\nLearning rate for epoch {} is {}'.format(        epoch + 1, model.optimizer.learning_rate.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the callbacks together.\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                       save_weights_only=True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
    "    PrintLR()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "Now, train the model in the usual way by calling Keras Model.fit on the model and passing in the dataset created at the beginning of the tutorial. This step is the same whether you are distributing the training or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 0.0391\n",
      "Learning rate for epoch 1 is 0.0010000000474974513\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 2/5\n",
      "\u001b[1m3749/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0263\n",
      "Learning rate for epoch 2 is 0.0010000000474974513\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 3/5\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0181\n",
      "Learning rate for epoch 3 is 0.0010000000474974513\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 4/5\n",
      "\u001b[1m3749/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0097\n",
      "Learning rate for epoch 4 is 9.999999747378752e-05\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m3743/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0048\n",
      "Learning rate for epoch 5 is 9.999999747378752e-05\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0048 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x171e6c23710>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "model.fit(train_dataset, epochs=EPOCHS, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ckpt_1.weights.h5',\n",
       " 'ckpt_2.weights.h5',\n",
       " 'ckpt_3.weights.h5',\n",
       " 'ckpt_4.weights.h5',\n",
       " 'ckpt_5.weights.h5']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(checkpoint_dir,'ckpt_5.weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0399\n",
      "Eval loss: 0.04309540241956711, Eval accuracy: 0.9883999824523926\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eval_loss, eval_acc = model.evaluate(eval_dataset)\n",
    "\n",
    "print('Eval loss: {}, Eval accuracy: {}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the output, launch TensorBoard and view the logs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'my_model.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0399\n",
      "Eval loss: 0.04309540241956711, Eval Accuracy: 0.9883999824523926\n"
     ]
    }
   ],
   "source": [
    "unreplicated_model = tf.keras.models.load_model(path)\n",
    "\n",
    "unreplicated_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "eval_loss, eval_acc = unreplicated_model.evaluate(eval_dataset)\n",
    "\n",
    "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\a27_YEARS_OLD\\deep_learning\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\a27_YEARS_OLD\\deep_learning\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0399\n",
      "Eval loss: 0.04309540241956711, Eval Accuracy: 0.9883999824523926\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  replicated_model = tf.keras.models.load_model(path)\n",
    "  replicated_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                           optimizer=tf.keras.optimizers.Adam(),\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "  eval_loss, eval_acc = replicated_model.evaluate(eval_dataset)\n",
    "  print ('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-db6eade5365acc20\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-db6eade5365acc20\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs/train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
