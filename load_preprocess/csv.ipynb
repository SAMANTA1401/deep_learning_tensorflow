{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In memory data\n",
    "For any small CSV dataset the simplest way to train a TensorFlow model on it is to load it into memory as a pandas DataFrame or a NumPy array.\n",
    "\n",
    "A relatively simple example is the abalone dataset.\n",
    "\n",
    "The dataset is small.\n",
    "All the input features are limited-range floating point values.\n",
    "Here is how to download the data into a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
       "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
       "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
       "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
       "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
       "\n",
       "   Shell weight  Age  \n",
       "0        0.0965    7  \n",
       "1        0.2250    6  \n",
       "2        0.3700   14  \n",
       "3        0.2600   16  \n",
       "4        0.2300   13  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_data = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "\n",
    "abalone_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nominal task for this dataset is to predict the age from the other measurements, so separate the features and labels for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_features = abalone_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
       "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
       "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
       "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
       "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
       "\n",
       "   Shell weight  Age  \n",
       "0        0.0965    7  \n",
       "1        0.2250    6  \n",
       "2        0.3700   14  \n",
       "3        0.2600   16  \n",
       "4        0.2300   13  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_train = abalone_features.drop('Age',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.3700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.2300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
       "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
       "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
       "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
       "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
       "\n",
       "   Shell weight  \n",
       "0        0.0965  \n",
       "1        0.2250  \n",
       "2        0.3700  \n",
       "3        0.2600  \n",
       "4        0.2300  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "abalone_labels = abalone_features.pop('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     7\n",
       "1     6\n",
       "2    14\n",
       "3    16\n",
       "4    13\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.435, 0.335, 0.11 , ..., 0.136, 0.077, 0.097],\n",
       "       [0.585, 0.45 , 0.125, ..., 0.354, 0.207, 0.225],\n",
       "       [0.655, 0.51 , 0.16 , ..., 0.396, 0.282, 0.37 ],\n",
       "       ...,\n",
       "       [0.53 , 0.42 , 0.13 , ..., 0.374, 0.167, 0.249],\n",
       "       [0.395, 0.315, 0.105, ..., 0.118, 0.091, 0.119],\n",
       "       [0.45 , 0.355, 0.12 , ..., 0.115, 0.067, 0.16 ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_train = np.array(abalone_train)\n",
    "abalone_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_model = tf.keras.Sequential([\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "abalone_model.compile(loss = tf.keras.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.5887\n",
      "Epoch 2/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.5996\n",
      "Epoch 3/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.2122\n",
      "Epoch 4/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.1487\n",
      "Epoch 5/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 6.2288\n",
      "Epoch 6/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.2159\n",
      "Epoch 7/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.9157\n",
      "Epoch 8/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4470\n",
      "Epoch 9/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.7114\n",
      "Epoch 10/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20ecc5f2150>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_model.fit(abalone_train, abalone_labels, epochs=10) #, metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic preprocessing\n",
    "It's good practice to normalize the inputs to your model. The Keras preprocessing layers provide a convenient way to build this normalization into your model.\n",
    "\n",
    "The tf.keras.layers.Normalization layer precomputes the mean and variance of each column, and uses these to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = layers.Normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize.adapt(abalone_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 88.6611\n",
      "Epoch 2/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41.5392\n",
      "Epoch 3/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.8929\n",
      "Epoch 4/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.3454\n",
      "Epoch 5/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.3189\n",
      "Epoch 6/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.1883\n",
      "Epoch 7/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8698\n",
      "Epoch 8/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 5.9705\n",
      "Epoch 9/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.2741\n",
      "Epoch 10/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20ecdaebe90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_abalone_model = tf.keras.Sequential([\n",
    "  normalize,\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "norm_abalone_model.compile(loss = tf.keras.losses.MeanSquaredError(),\n",
    "                           optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "norm_abalone_model.fit(abalone_train, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "titanik\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixed data types\n",
    "In the previous sections, you worked with a dataset where all the features were limited-range floating point values. But not all datasets are limited to a single data type.\n",
    "\n",
    "The \"Titanic\" dataset contains information about the passengers on the Titanic. The nominal task on this dataset is to predict who survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the different data types and ranges, you can't simply stack the features into a NumPy array and pass it to a tf.keras.Sequential model. Each column needs to be handled individually.\n",
    "\n",
    "As one option, you could preprocess your data offline (using any tool you like) to convert categorical columns to numeric columns, then pass the processed output to your TensorFlow model. The disadvantage to that approach is that if you save and export your model the preprocessing is not saved with it. The Keras preprocessing layers avoid this problem because they're part of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None,), dtype=float32, sparse=False, name=keras_tensor_9>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a symbolic input\n",
    "input = tf.keras.Input(shape=(), dtype=tf.float32)\n",
    "\n",
    "# Perform a calculation using the input\n",
    "result = 2*input + 1 # y = mx +c\n",
    "\n",
    "# the result doesn't have a value\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None,), dtype=float32, sparse=False, name=keras_tensor_7>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = tf.keras.Model(inputs=input, outputs=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Functional name=functional_2, built=True>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n",
      "[5.]\n"
     ]
    }
   ],
   "source": [
    "print(calc(np.array([1])).numpy())\n",
    "print(calc(np.array([2])).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sex',\n",
       " 0        male\n",
       " 1      female\n",
       " 2      female\n",
       " 3      female\n",
       " 4        male\n",
       "         ...  \n",
       " 622      male\n",
       " 623      male\n",
       " 624    female\n",
       " 625    female\n",
       " 626      male\n",
       " Name: sex, Length: 627, dtype: object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(titanic_features.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sex',\n",
       " 0        male\n",
       " 1      female\n",
       " 2      female\n",
       " 3      female\n",
       " 4        male\n",
       "         ...  \n",
       " 622      male\n",
       " 623      male\n",
       " 624    female\n",
       " 625    female\n",
       " 626      male\n",
       " Name: sex, Length: 627, dtype: object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(titanic_features.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line creates a Keras input layer and adds it to the inputs dictionary:\n",
    "Code Breakdown\n",
    "tf.keras.Input(): Creates a Keras input layer.\n",
    "shape=(1,): Specifies the input shape (scalar value).\n",
    "name=name: Assigns a name to the input layer.\n",
    "dtype=dtype: Specifies the data type (e.g., float32, int32).\n",
    "inputs[name] = ...: Adds the input layer to the inputs dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=sex>,\n",
       " 'age': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=age>,\n",
       " 'n_siblings_spouses': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=n_siblings_spouses>,\n",
       " 'parch': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=parch>,\n",
       " 'fare': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=fare>,\n",
       " 'class': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=class>,\n",
       " 'deck': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=deck>,\n",
       " 'embark_town': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=embark_town>,\n",
       " 'alone': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=alone>}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# inputs = {}\n",
    "# dtype = tf.float32\n",
    "\n",
    "# # Create input layers for 'age' and 'height'\n",
    "# for name in ['age', 'height']:\n",
    "#     inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "# print(inputs)\n",
    "# # Output: {'age': <KerasTensor>, 'height': <KerasTensor>}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_features['class'].dtype #object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['class'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in your preprocessing logic is to concatenate the numeric inputs together, and run them through a normalization layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=age>,\n",
       " 'n_siblings_spouses': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=n_siblings_spouses>,\n",
       " 'parch': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=parch>,\n",
       " 'fare': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=fare>}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([<KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=age>, <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=n_siblings_spouses>, <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=parch>, <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=fare>])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_inputs = {name:input for name,input in inputs.items() \n",
    "                      if input.dtype == tf.string}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=sex>,\n",
       " 'class': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=class>,\n",
       " 'deck': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=deck>,\n",
       " 'embark_town': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=embark_town>,\n",
       " 'alone': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=alone>}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line of code concatenates multiple numeric input features into a single tensor using the Keras Concatenate layer:\n",
    "Code Breakdown\n",
    "numeric_inputs.values(): Extracts values from the numeric_inputs dictionary.\n",
    "list(numeric_inputs.values()): Converts the dictionary values into a list.\n",
    "layers.Concatenate(): Creates a Concatenate layer instance.\n",
    "x = layers.Concatenate()(list(numeric_inputs.values())): Concatenates the input features along the last axis (axis=-1) and assigns the result to x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_inputs = {\n",
    "#     'age': layers.Input(shape=(1,), name='age'),\n",
    "#     'height': layers.Input(shape=(1,), name='height'),\n",
    "#     'weight': layers.Input(shape=(1,), name='weight')\n",
    "# }\n",
    "\n",
    "# x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "# print(x.shape)  # Output: (None, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 4), dtype=float32, sparse=False, name=keras_tensor_10>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = layers.Normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Normalization name=normalization_1, built=False>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 4), dtype=float32, sparse=False, name=keras_tensor_12>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_numeric_inputs = norm(x) # normalization for numerical inputs\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the string inputs use the tf.keras.layers.StringLookup function to map from strings to integer indices in a vocabulary. Next, use tf.keras.layers.CategoryEncoding to convert the indexes into float32 data appropriate for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "\n",
    "  lookup = layers.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "  one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a lookup table: Maps string values to integer indices.\n",
    "Vocabulary: Set to unique values in titanic_features[name].\n",
    "lookup.vocabulary_size(): Returns the number of unique strings.\n",
    "CategoryEncoding Layer (One-Hot Encoding)\n",
    "Converts integer indices to one-hot vectors.\n",
    "num_tokens: Set to the vocabulary size from StringLookup.\n",
    "Output shape: (batch_size, vocabulary_size)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the collection of inputs and preprocessed_inputs, you can concatenate all the preprocessed inputs together, and build a model that handles the preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 28), dtype=float32, sparse=False, name=keras_tensor_23>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_inputs_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Functional name=functional_3, built=True>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model = titanic_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-3.0.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in d:\\a27_years_old\\deep_learning\\venv\\lib\\site-packages (from pydot) (3.2.0)\n",
      "Downloading pydot-3.0.2-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-3.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model just contains the input preprocessing. You can run it to see what it does to your data. Keras models don't automatically convert pandas DataFrames because it's not clear if it should be converted to one tensor or to a dictionary of tensors. So, convert it to a dictionary of tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features_dict = {name: np.array(value) \n",
    "                        for name, value in titanic_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck',\n",
       "       'embark_town', 'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Third\n",
       "1       First\n",
       "2       Third\n",
       "3       First\n",
       "4       Third\n",
       "        ...  \n",
       "622    Second\n",
       "623     Third\n",
       "624     First\n",
       "625     Third\n",
       "626     Third\n",
       "Name: class, Length: 627, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_features['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice out the first training example and pass it to this preprocessing model, you see the numeric features and string one-hots all concatenated together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': array(['male'], dtype=object),\n",
       " 'age': array([22.]),\n",
       " 'n_siblings_spouses': array([1]),\n",
       " 'parch': array([0]),\n",
       " 'fare': array([7.25]),\n",
       " 'class': array(['Third'], dtype=object),\n",
       " 'deck': array(['unknown'], dtype=object),\n",
       " 'embark_town': array(['Southampton'], dtype=object),\n",
       " 'alone': array(['n'], dtype=object)}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 28), dtype=float32, numpy=\n",
       "array([[-0.61 ,  0.395, -0.479, -0.497,  0.   ,  0.   ,  1.   ,  0.   ,\n",
       "         0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "         0.   ,  0.   ,  1.   ,  0.   ]], dtype=float32)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, build the model on top of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_model(preprocessing_head, inputs):\n",
    "  body = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  preprocessed_inputs = preprocessing_head(inputs)\n",
    "  result = body(preprocessed_inputs)\n",
    "  model = tf.keras.Model(inputs, result)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam())\n",
    "  return model\n",
    "\n",
    "titanic_model = titanic_model(titanic_preprocessing, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you train the model, pass the dictionary of features as x, and the label as y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.6483\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5590\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5425\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5193\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4789 \n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4609\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4409\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4470\n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4170\n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20eceea4e10>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_model.save('test.keras')\n",
    "reloaded = tf.keras.models.load_model('test.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-1.888]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[-1.888]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "\n",
    "before = titanic_model(features_dict)\n",
    "after = reloaded(features_dict)\n",
    "assert (before-after)<1e-3\n",
    "print(before)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def slices(features):\n",
    "  for i in itertools.count():\n",
    "    # For each feature take index `i`\n",
    "    example = {name:values[i] for name, values in features.items()}\n",
    "    yield example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : male\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : Third\n",
      "deck               : unknown\n",
      "embark_town        : Southampton\n",
      "alone              : n\n"
     ]
    }
   ],
   "source": [
    "for example in slices(titanic_features_dict):\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic tf.data.Dataset in memory data loader is the Dataset.from_tensor_slices constructor. This returns a tf.data.Dataset that implements a generalized version of the above slices function, in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ds = tf.data.Dataset.from_tensor_slices(titanic_features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The from_tensor_slices function can handle any structure of nested dictionaries or tuples. The following code makes a dataset of (features_dict, labels) pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_ds = tf.data.Dataset.from_tensor_slices((titanic_features_dict, titanic_labels)) # double parentheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model using this Dataset, you'll need to at least shuffle and batch the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_batches = titanic_ds.shuffle(len(titanic_labels)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.4277 \n",
      "Epoch 2/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4238 \n",
      "Epoch 3/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4004\n",
      "Epoch 4/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3953\n",
      "Epoch 5/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20ecf192350>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_model.fit(titanic_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
      "\u001b[1m30874/30874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step\n"
     ]
    }
   ],
   "source": [
    "# titanic_file_path = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.get_file(\n",
    "#     filename,\n",
    "#     origin,\n",
    "#     untar=False,\n",
    "#     extract=False,\n",
    "#     archive_format='auto',\n",
    "#     cache_subdir='models'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read csv from file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
      "\u001b[1m30874/30874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step\n"
     ]
    }
   ],
   "source": [
    "titanic_file_path = tf.keras.utils.get_file('train.csv',cache_subdir=os.getcwd(), origin=\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\a27_YEARS_OLD\\deep_learning\\venv\\Lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\readers.py:572: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.ignore_errors` instead.\n"
     ]
    }
   ],
   "source": [
    "titanic_csv_ds = tf.data.experimental.make_csv_dataset(\n",
    "    titanic_file_path,\n",
    "    batch_size=5, # Artificially small to make examples easier to show.\n",
    "    label_name='survived',\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(OrderedDict([('sex', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('age', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('n_siblings_spouses', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('parch', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('fare', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('class', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('deck', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('embark_town', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('alone', TensorSpec(shape=(None,), dtype=tf.string, name=None))]), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_csv_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function includes many convenient features, so the data is easy to work with. This includes:\n",
    "\n",
    "Using the column headers as dictionary keys.\n",
    "Automatically determining the type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                 : [b'male' b'male' b'male' b'female' b'female']\n",
      "age                 : [36. 22. 59.  4. 18.]\n",
      "n_siblings_spouses  : [1 0 0 0 0]\n",
      "parch               : [2 0 0 1 1]\n",
      "fare                : [27.75   7.25  13.5   13.417  9.35 ]\n",
      "class               : [b'Second' b'Third' b'Second' b'Third' b'Third']\n",
      "deck                : [b'unknown' b'unknown' b'unknown' b'unknown' b'unknown']\n",
      "embark_town         : [b'Southampton' b'Southampton' b'Southampton' b'Cherbourg' b'Southampton']\n",
      "alone               : [b'n' b'y' b'y' b'n' b'n']\n",
      "\n",
      "label               : [0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "for batch, label in titanic_csv_ds.take(1):\n",
    "  for key, value in batch.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "  print()\n",
    "  print(f\"{'label':20s}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read csv from zip compressed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\n",
      " 409600/Unknown \u001b[1m1s\u001b[0m 3us/step"
     ]
    }
   ],
   "source": [
    "traffic_volume_csv_gz = tf.keras.utils.get_file(\n",
    "    'Metro_Interstate_Traffic_Volume.csv.gz', \n",
    "     origin = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\",\n",
    "     cache_subdir=os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the compression_type argument to read directly from the compressed file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_volume_csv_gz_ds = tf.data.experimental.make_csv_dataset(\n",
    "    traffic_volume_csv_gz,\n",
    "    batch_size=256,\n",
    "    label_name='traffic_volume',\n",
    "    num_epochs=1,\n",
    "    compression_type=\"GZIP\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holiday             : [b'None' b'None' b'None' b'None' b'None']\n",
      "temp                : [280.15 294.9  287.13 286.3  296.55]\n",
      "rain_1h             : [0. 0. 0. 0. 0.]\n",
      "snow_1h             : [0. 0. 0. 0. 0.]\n",
      "clouds_all          : [90 90 90 90 36]\n",
      "weather_main        : [b'Clouds' b'Drizzle' b'Clouds' b'Rain' b'Rain']\n",
      "weather_description : [b'overcast clouds' b'light intensity drizzle' b'overcast clouds'\n",
      " b'light rain' b'light rain']\n",
      "date_time           : [b'2012-10-05 19:00:00' b'2013-06-13 19:00:00' b'2013-05-28 01:00:00'\n",
      " b'2013-05-29 11:00:00' b'2013-06-12 15:00:00']\n",
      "\n",
      "label               : [4063 3487  345 4811 5948]\n"
     ]
    }
   ],
   "source": [
    "for batch, label in traffic_volume_csv_gz_ds.take(1):\n",
    "  for key, value in batch.items():\n",
    "    print(f\"{key:20s}: {value[:5]}\")\n",
    "  print()\n",
    "  print(f\"{'label':20s}: {label[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caching\n",
    "There is some overhead to parsing the CSV data. For small models this can be the bottleneck in training.\n",
    "\n",
    "Depending on your use case, it may be a good idea to use Dataset.cache or tf.data.Dataset.snapshot, so that the CSV data is only parsed on the first epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or example, iterating over the traffic_volume_csv_gz_ds 20 times may take around 15 seconds without caching, or about two seconds with caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "CPU times: total: 15.3 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, (batch, label) in enumerate(traffic_volume_csv_gz_ds.repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "CPU times: total: 2.23 s\n",
      "Wall time: 1.99 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "caching = traffic_volume_csv_gz_ds.cache().shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(caching.shuffle(1000).repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "CPU times: total: 3.41 s\n",
      "Wall time: 3.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "snapshotting = traffic_volume_csv_gz_ds.snapshot('titanic.tfsnap').shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(snapshotting.shuffle(1000).repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple files\n",
    "All the examples so far in this section could easily be done without tf.data. One place where tf.data can really simplify things is when dealing with collections of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\n",
      "160096256/Unknown \u001b[1m39s\u001b[0m 0us/step"
     ]
    }
   ],
   "source": [
    "fonts_zip = tf.keras.utils.get_file(\n",
    "    'fonts.zip',  origin = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\",\n",
    "    cache_subdir=os.getcwd(),\n",
    "    extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_path = os.path.join(os.getcwd()+'/'+'fonts_extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:\\\\a27_YEARS_OLD\\\\deep_learning\\\\load_preprocess\\\\fonts_extracted\\\\AGENCY.csv',\n",
       " 'd:\\\\a27_YEARS_OLD\\\\deep_learning\\\\load_preprocess\\\\fonts_extracted\\\\ARIAL.csv',\n",
       " 'd:\\\\a27_YEARS_OLD\\\\deep_learning\\\\load_preprocess\\\\fonts_extracted\\\\BAITI.csv',\n",
       " 'd:\\\\a27_YEARS_OLD\\\\deep_learning\\\\load_preprocess\\\\fonts_extracted\\\\BANKGOTHIC.csv',\n",
       " 'd:\\\\a27_YEARS_OLD\\\\deep_learning\\\\load_preprocess\\\\fonts_extracted\\\\BASKERVILLE.csv',\n",
       " 'd:\\\\a27_YEARS_OLD\\\\deep_learning\\\\load_preprocess\\\\fonts_extracted\\\\BAUHAUS.csv',\n",
       " 'd:\\\\a27_YEARS_OLD\\\\deep_learning\\\\load_preprocess\\\\fonts_extracted\\\\BELL.csv',\n",
       " 'd:\\\\a27_YEARS_OLD\\\\deep_learning\\\\load_preprocess\\\\fonts_extracted\\\\BERLIN.csv',\n",
       " 'd:\\\\a27_YEARS_OLD\\\\deep_learning\\\\load_preprocess\\\\fonts_extracted\\\\BERNARD.csv',\n",
       " 'd:\\\\a27_YEARS_OLD\\\\deep_learning\\\\load_preprocess\\\\fonts_extracted\\\\BITSTREAMVERA.csv']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "font_csvs =  sorted(str(p) for p in pathlib.Path(extract_path).glob(\"*.csv\"))\n",
    "\n",
    "font_csvs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(font_csvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with a bunch of files, you can pass a glob-style file_pattern to the tf.data.experimental.make_csv_dataset function. The order of the files is shuffled each iteration.\n",
    "\n",
    "Use the num_parallel_reads argument to set how many files are read in parallel and interleaved together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = \"fonts_extracted/*.csv\",\n",
    "    batch_size=10, num_epochs=1,\n",
    "    num_parallel_reads=20,\n",
    "    shuffle_buffer_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=OrderedDict([('font', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('fontVariant', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('m_label', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('strength', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('italic', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('orientation', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('m_top', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('m_left', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('originalH', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('originalW', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('h', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('w', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r0c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r1c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r2c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r3c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r4c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r5c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r6c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r7c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r8c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r9c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r10c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r11c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r12c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r13c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r14c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r15c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r16c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r17c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r18c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c0', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c1', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c2', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c3', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c4', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c5', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c6', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c7', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c8', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c9', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c10', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c11', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c12', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c13', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c14', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c15', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c16', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c17', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c18', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('r19c19', TensorSpec(shape=(None,), dtype=tf.int32, name=None))])>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fonts_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These CSV files have the images flattened out into a single row. The column names are formatted r{row}c{column}. Here's the first batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "font                : [b'FREESTYLE' b'HARRINGTON' b'BANKGOTHIC' b'HIGH TOWER' b'LEELAWADEE'\n",
      " b'CAARD' b'GILL' b'FRENCH' b'LEELAWADEE' b'FREESTYLE']\n",
      "fontVariant         : [b'FREESTYLE SCRIPT' b'HARRINGTON' b'BANKGOTHIC MD BT' b'HIGH TOWER TEXT'\n",
      " b'LEELAWADEE UI SEMILIGHT' b'CAARD-LN' b'GILL SANS ULTRA BOLD CONDENSED'\n",
      " b'FRENCH SCRIPT MT' b'LEELAWADEE UI SEMILIGHT' b'FREESTYLE SCRIPT']\n",
      "m_label             : [ 188   83  213 8225 6627  109   77  187 7880  249]\n",
      "strength            : [0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]\n",
      "italic              : [0 1 0 1 0 0 0 1 0 1]\n",
      "orientation         : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "m_top               : [38 36 27 36 38 34 36 57 29 41]\n",
      "m_left              : [26 24 28 21 28 20 23 24 24 20]\n",
      "originalH           : [39 48 47 45 61 47 50 18 63 35]\n",
      "originalW           : [32 40 43 25 35 26 42 23  9 29]\n",
      "h                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "w                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "r0c0                : [  1   1   1   1   2  64 255   1 243   1]\n",
      "r0c1                : [  1   1   1   1 100 197 255   1 243   1]\n",
      "r0c2                : [  1   1   1   1 172 255 255   1 243   1]\n",
      "r0c3                : [  1   1   1   1 220 255 255   1 243   1]\n",
      "...\n",
      "[total: 412 features]\n"
     ]
    }
   ],
   "source": [
    "for features in fonts_ds.take(1):\n",
    "  for i, (name, value) in enumerate(features.items()):\n",
    "    if i>15:\n",
    "      break\n",
    "    print(f\"{name:20s}: {value}\")\n",
    "print('...')\n",
    "print(f\"[total: {len(features)} features]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Packing fields\n",
    "You probably don't want to work with each pixel in separate columns like this. Before trying to use this dataset be sure to pack the pixels into an image-tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize: Creates an empty list image of size 400 and an empty dictionary new_feats.\n",
    "Pattern Matching: Iterates through features, using regular expressions to match keys resembling \"rXdYcZ\" (row X, column Z).\n",
    "Image Construction: Assigns matched values to corresponding indices in the image list.\n",
    "Non-Image Features: Stores non-matched key-value pairs in new_feats.\n",
    "Image Reshaping: Converts the image list to a TensorFlow tensor, reshaping it into a 20x20x1 image.\n",
    "Combining Features: Adds the transformed image to new_feats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def make_images(features):\n",
    "  image = [None]*400\n",
    "  new_feats = {}\n",
    "\n",
    "  for name, value in features.items():\n",
    "    match = re.match('r(\\d+)c(\\d+)', name)\n",
    "    if match:\n",
    "      image[int(match.group(1))*20+int(match.group(2))] = value\n",
    "    else:\n",
    "      new_feats[name] = value\n",
    "\n",
    "  image = tf.stack(image, axis=0)\n",
    "  image = tf.reshape(image, [20, 20, -1])\n",
    "  new_feats['image'] = image\n",
    "\n",
    "  return new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_image_ds = fonts_ds.map(make_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for features in fonts_image_ds.take(1):\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,6), dpi=120)\n",
    "\n",
    "for n in range(9):\n",
    "  plt.subplot(3,3,n+1)\n",
    "  plt.imshow(features['image'][..., n])\n",
    "  plt.title(chr(features['m_label'][n]))\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pathlib.Path(titanic_file_path).read_text()\n",
    "lines = text.split('\\n')[1:-1]\n",
    "\n",
    "all_strings = [str()]*10\n",
    "all_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n"
     ]
    }
   ],
   "source": [
    "features = tf.io.decode_csv(lines, record_defaults=all_strings) \n",
    "\n",
    "for f in features:\n",
    "  print(f\"type: {f.dtype.name}, shape: {f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, '', 0.0, 0, 0, 0.0, '', '', '', '']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_types = [int(), str(), float(), int(), int(), float(), str(), str(), str(), str()]\n",
    "titanic_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int32(0), b'male', np.float32(22.0), np.int32(1), np.int32(0), np.float32(7.25), b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "simple_titanic = tf.data.experimental.CsvDataset(titanic_file_path, record_defaults=titanic_types, header=True)\n",
    "\n",
    "for example in simple_titanic.take(1):\n",
    "  print([e.numpy() for e in example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int32(0), b'male', np.float32(22.0), np.int32(1), np.int32(0), np.float32(7.25), b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "def decode_titanic_line(line):\n",
    "  return tf.io.decode_csv(line, titanic_types)\n",
    "\n",
    "manual_titanic = (\n",
    "    # Load the lines of text\n",
    "    tf.data.TextLineDataset(titanic_file_path)\n",
    "    # Skip the header row.\n",
    "    .skip(1)\n",
    "    # Decode the line.\n",
    "    .map(decode_titanic_line)\n",
    ")\n",
    "\n",
    "for example in manual_titanic.take(1):\n",
    "  print([e.numpy() for e in example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple files\n",
    "To parse the fonts dataset using tf.data.experimental.CsvDataset, you first need to determine the column types for the record_defaults. Start by inspecting the first row of one file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENCY,AGENCY FB,64258,0.400000,0,0.000000,35,21,51,22,20,20,1,1,1,21,101,210,255,255,255,255,255,255,255,255,255,255,255,255,255,255,1,1,1,93,255,255,255,176,146,146,146,146,146,146,146,146,216,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,141,141,141,182,255,255,255,172,141,141,141,115,1,1,1,1,163,255,255,255,255,255,255,255,255,255,255,255,255,255,255,209,1,1,1,1,163,255,255,255,6,6,6,96,255,255,255,74,6,6,6,5,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255\n"
     ]
    }
   ],
   "source": [
    "font_line = pathlib.Path(font_csvs[0]).read_text().splitlines()[1]\n",
    "print(font_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_font_features = font_line.count(',')+1\n",
    "font_column_types = [str(), str()] + [float()]*(num_font_features-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\a27_YEARS_OLD\\\\deep_learning\\\\load_preprocess\\\\fonts_extracted\\\\AGENCY.csv'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "font_csvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_font_ds = tf.data.experimental.CsvDataset(\n",
    "    font_csvs, \n",
    "    record_defaults=font_column_types, \n",
    "    header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n"
     ]
    }
   ],
   "source": [
    "for row in simple_font_ds.take(10):\n",
    "  print(row[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: fonts/*.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m font_files \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfonts/*.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\a27_YEARS_OLD\\deep_learning\\venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1329\u001b[0m, in \u001b[0;36mDatasetV2.list_files\u001b[1;34m(file_pattern, shuffle, seed, name)\u001b[0m\n\u001b[0;32m   1322\u001b[0m condition \u001b[38;5;241m=\u001b[39m math_ops\u001b[38;5;241m.\u001b[39mgreater(array_ops\u001b[38;5;241m.\u001b[39mshape(matching_files)[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   1323\u001b[0m                              name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch_not_empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1325\u001b[0m message \u001b[38;5;241m=\u001b[39m math_ops\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo files matched pattern: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1327\u001b[0m     string_ops\u001b[38;5;241m.\u001b[39mreduce_join(file_pattern, separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1329\u001b[0m assert_not_empty \u001b[38;5;241m=\u001b[39m \u001b[43mcontrol_flow_assert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAssert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massert_not_empty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies([assert_not_empty]):\n\u001b[0;32m   1332\u001b[0m   matching_files \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39midentity(matching_files)\n",
      "File \u001b[1;32md:\\a27_YEARS_OLD\\deep_learning\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\a27_YEARS_OLD\\deep_learning\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\control_flow_assert.py:102\u001b[0m, in \u001b[0;36mAssert\u001b[1;34m(condition, data, summarize, name)\u001b[0m\n\u001b[0;32m    100\u001b[0m     xs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_n_to_tensor(data)\n\u001b[0;32m    101\u001b[0m     data_str \u001b[38;5;241m=\u001b[39m [_summarize_eager(x, summarize) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xs]\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError(\n\u001b[0;32m    103\u001b[0m         node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    104\u001b[0m         op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    105\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be true. Summarized data: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    106\u001b[0m         (condition, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(data_str)))\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssert\u001b[39m\u001b[38;5;124m\"\u001b[39m, [condition, data]) \u001b[38;5;28;01mas\u001b[39;00m name:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: fonts/*.csv'"
     ]
    }
   ],
   "source": [
    "font_files = tf.data.Dataset.list_files(\"fonts/*.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Epoch 1:')\n",
    "for f in list(font_files)[:5]:\n",
    "  print(\"    \", f.numpy())\n",
    "print('    ...')\n",
    "print()\n",
    "\n",
    "print('Epoch 2:')\n",
    "for f in list(font_files)[:5]:\n",
    "  print(\"    \", f.numpy())\n",
    "print('    ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_font_csv_ds(path):\n",
    "  return tf.data.experimental.CsvDataset(\n",
    "    path, \n",
    "    record_defaults=font_column_types, \n",
    "    header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_rows = font_files.interleave(make_font_csv_ds,\n",
    "                                  cycle_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_dict = {'font_name':[], 'character':[]}\n",
    "\n",
    "for row in font_rows.take(10):\n",
    "  fonts_dict['font_name'].append(row[0].numpy().decode())\n",
    "  fonts_dict['character'].append(chr(int(row[2].numpy())))\n",
    "\n",
    "pd.DataFrame(fonts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=2048\n",
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = \"fonts/*.csv\",\n",
    "    batch_size=BATCH_SIZE, num_epochs=1,\n",
    "    num_parallel_reads=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i,batch in enumerate(fonts_ds.take(20)):\n",
    "  print('.',end='')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_files = tf.data.Dataset.list_files(\"fonts/*.csv\")\n",
    "fonts_lines = fonts_files.interleave(\n",
    "    lambda fname:tf.data.TextLineDataset(fname).skip(1), \n",
    "    cycle_length=100).batch(BATCH_SIZE)\n",
    "\n",
    "fonts_fast = fonts_lines.map(lambda x: tf.io.decode_csv(x, record_defaults=font_column_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i,batch in enumerate(fonts_fast.take(20)):\n",
    "  print('.',end='')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
